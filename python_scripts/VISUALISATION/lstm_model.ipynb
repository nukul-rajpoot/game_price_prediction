{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import median_absolute_error\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "from python_scripts.api_calls import fetch_item_to_df, fetch_items, get_cookie_from_blob\n",
    "\n",
    "\n",
    "dailyCookie = get_cookie_from_blob()\n",
    "items = fetch_items()\n",
    "\n",
    "current_item = fetch_item_to_df(items[4], dailyCookie)\n",
    "#print(items[4])\n",
    "\n",
    "#print(current_item.tail())\n",
    "#print(non_aggregated_item.tail())\n",
    "\n",
    "df = current_item\n",
    "\n",
    "os. getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert an array of values into a dataset matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    " dataX, dataY = [], []\n",
    " #print(len(dataset))\n",
    " for i in range(len(dataset)-look_back-1):\n",
    "    a = dataset[i:(i+look_back), 0]\n",
    "    dataX.append(a)\n",
    "    dataY.append(dataset[i + look_back, 0])\n",
    " return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "#printx,printy = create_dataset(dataset, 1)\n",
    "#print(printx)\n",
    "\n",
    "#Takes in np array and returns new orignal array with shifted values (look_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads and normalises dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = df[\"price_usd\"]\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "dataset = processed_df.values\n",
    "dataset = dataset.astype('float32')\n",
    "print(dataset)\n",
    "#print(processed_df)\n",
    "#normalize the dataset\n",
    "dataset = dataset.reshape(-1, 1)\n",
    "print(dataset)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "test_size = int(len(dataset) * 0.9)\n",
    "\n",
    "train, test = dataset[0:train_size], dataset[train_size:test_size]\n",
    "\n",
    "print(len(train), len(test))\n",
    "\n",
    "\n",
    "\n",
    "# train_size = int(len(dataset) * 0.67)\n",
    "\n",
    "# X_train, X_test = X[:split_point], X[split_point:]\n",
    "# y_train, y_test = y[:split_point], y[split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshapes into X=t and Y=t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print((testX))\n",
    "print((testY))\n",
    "counter = 0\n",
    "for i in range(len(train)-look_back-1):\n",
    "        counter+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshapes input for samples, timesteps and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(trainX.shape[1])\n",
    "\n",
    "#trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "#testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "#print(trainX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates and fit the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=2, batch_size=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes predictions, inverts predictions, and calculate root mean sqaured error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# invert predictions\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "unscaledtrainY = scaler.inverse_transform([trainY])\n",
    "unscaledtestPredict = scaler.inverse_transform(testPredict)\n",
    "unscaledtestY = scaler.inverse_transform([testY])\n",
    "rowunscaledtestY = unscaledtestY.reshape(-1,1)\n",
    "# calculate root mean squared error\n",
    "#trainScore = np.sqrt(mean_squared_error(scaledtrainY[0], trainPredict[:,0]))\n",
    "\n",
    "#print(unscaledtestY, unscaledtestPredict)\n",
    "\n",
    "#print(testPredict)\n",
    "#print(testY)\n",
    "print(unscaledtestY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScore = np.sqrt(mean_squared_error(unscaledtestY[0], unscaledtestPredict[:,0]))  #Root mean squared error\n",
    "r2 = r2_score(unscaledtestY[0], unscaledtestPredict[:, 0]) #R2 score - This provides an indication of the goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model. It is the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "explained_variance = explained_variance_score(unscaledtestY[0], unscaledtestPredict[:, 0])  #Explained variance score  this measures the proportion to which a mathematical model accounts for the variation (dispersion) of a given data set. It is the proportion of the variance in the dependent variable that is predictable from the independent variables\n",
    "medae = median_absolute_error(unscaledtestY[0], unscaledtestPredict[:, 0])\n",
    "mae = mean_absolute_error(unscaledtestY[0], unscaledtestPredict[:, 0])\n",
    "mape = np.mean(np.abs((unscaledtestY[0] - unscaledtestPredict[:, 0]) / unscaledtestY[0])) * 100\n",
    "\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "print('R2 Score: %.2f' % (r2))\n",
    "print('Explained Variance: %.2f' % (explained_variance))\n",
    "print('Median Absolute Error: %.2f' % (medae))\n",
    "print('Mean Absolute Error: %.2f' % (mae))\n",
    "print('Mean Absolute Percentage Error: %.2f' % (mape)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifts predicitons and plots graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shift train predictions for plotting\n",
    "# trainPredictPlot = np.empty_like(dataset)\n",
    "\n",
    "# trainPredictPlot[:, :] = np.nan\n",
    "\n",
    "# #trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"LSTM - Predicted vs Actual\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.plot(unscaledtestPredict , label = \"Predicted\") #yÌ„\n",
    "plt.plot(rowunscaledtestY, label = \"Actual\") #ground truth values\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "print(testScore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
