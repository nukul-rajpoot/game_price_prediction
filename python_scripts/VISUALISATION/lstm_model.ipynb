{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "from python_scripts.api_calls import fetch_item_to_df, fetch_items, get_cookie_from_blob\n",
    "\n",
    "\n",
    "dailyCookie = get_cookie_from_blob()\n",
    "items = fetch_items()\n",
    "\n",
    "current_item = fetch_item_to_df(items[4], dailyCookie)\n",
    "#print(items[4])\n",
    "\n",
    "#print(current_item.tail())\n",
    "#print(non_aggregated_item.tail())\n",
    "\n",
    "df = current_item\n",
    "\n",
    "os. getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert an array of values into a dataset matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    " dataX, dataY = [], []\n",
    " print(len(dataset))\n",
    " for i in range(len(dataset)-look_back-1):\n",
    "    a = dataset[i:(i+look_back), 0]\n",
    "    dataX.append(a)\n",
    "    dataY.append(dataset[i + look_back, 0])\n",
    " return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "#printx,printy = create_dataset(dataset, 1)\n",
    "#print(printx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads and normalises dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = df[\"price_usd\"]\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "dataset = processed_df.values\n",
    "dataset = dataset.astype('float32')\n",
    "print(dataset)\n",
    "#print(processed_df)\n",
    "#normalize the dataset\n",
    "dataset = dataset.reshape(-1, 1)\n",
    "print(dataset)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
    "\n",
    "print(len(train), len(test))\n",
    "\n",
    "\n",
    "\n",
    "# train_size = int(len(dataset) * 0.67)\n",
    "\n",
    "# X_train, X_test = X[:split_point], X[split_point:]\n",
    "# y_train, y_test = y[:split_point], y[split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshapes into X=t and Y=t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "#print(len(train))\n",
    "#print(len(trainX))\n",
    "#print(len(trainY))\n",
    "counter = 0\n",
    "for i in range(len(train)-look_back-1):\n",
    "        counter+=1\n",
    "        \n",
    "print (counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshapes input for samples, timesteps and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates and fit the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes predictions, inverts predictions, and calculate root mean sqaured error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# invert predictions\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "unscaledtrainY = scaler.inverse_transform([trainY])\n",
    "unscaledtestPredict = scaler.inverse_transform(testPredict)\n",
    "unscaledtestY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate root mean squared error\n",
    "#trainScore = np.sqrt(mean_squared_error(scaledtrainY[0], trainPredict[:,0]))\n",
    "#print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(unscaledtestY[0], unscaledtestPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "print(unscaledtestY, unscaledtestPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifts predicitons and plots graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "print(len(unscaledtestPredict))\n",
    "print(len(unscaledtestY))\n",
    "#trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "#testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "# plt.plot(scaler.inverse_transform(dataset))\n",
    "# plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "# test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
