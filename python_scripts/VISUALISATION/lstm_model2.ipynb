{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "from python_scripts.api_calls import fetch_item_to_df, fetch_items, get_cookie_from_blob\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "dailyCookie = get_cookie_from_blob()\n",
    "items = fetch_items()\n",
    "\n",
    "current_item = fetch_item_to_df(items[4], dailyCookie)\n",
    "#print(items[4])\n",
    "\n",
    "#print(current_item.tail())\n",
    "#print(non_aggregated_item.tail())\n",
    "\n",
    "df = current_item\n",
    "\n",
    "os. getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values if any\n",
    "df = df.fillna(method='ffill')\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['scaled_price'] = scaler.fit_transform(df[['price_usd']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 1  # Length of the sequence\n",
    "\n",
    "# Create columns for each step in the sequence\n",
    "for i in range(1, seq_length + 1):\n",
    "    df[f't-{i}'] = df['scaled_price'].shift(i)\n",
    "\n",
    "# Drop rows with NaN values that were introduced by shifting\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels = [f't-{i}' for i in range(1, seq_length + 1)]\n",
    "y_label = 'scaled_price'\n",
    "\n",
    "X = df[X_labels]\n",
    "y = df[y_label]\n",
    "\n",
    "split_train = int(0.7 * len(X))  # First 70% for training\n",
    "split_test = int(0.9 * len(X))   # Next 20% for testing, leaving last 10% for validation\n",
    "\n",
    "# Split the data\n",
    "X_train = X[:split_train]\n",
    "y_train = y[:split_train]\n",
    "\n",
    "X_test = X[split_train:split_test]\n",
    "y_test = y[split_train:split_test]\n",
    "\n",
    "X_val = X[split_test:]\n",
    "y_val = y[split_test:]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates and fit the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes predictions, inverts predictions, and calculate root mean sqaured error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(X_test)\n",
    "\n",
    "# invert predictions\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "unscaledtrainY = scaler.inverse_transform([y_train])\n",
    "unscaledtestPredict = scaler.inverse_transform(testPredict)\n",
    "unscaledtestY = scaler.inverse_transform([y_test])\n",
    "rowunscaledtestY = unscaledtestY.reshape(-1,1)\n",
    "# calculate root mean squared error\n",
    "#trainScore = np.sqrt(mean_squared_error(scaledtrainY[0], trainPredict[:,0]))\n",
    "\n",
    "#print(unscaledtestY, unscaledtestPredict)\n",
    "\n",
    "#print(testPredict)\n",
    "#print(testY)\n",
    "#print(unscaledtestY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScore = np.sqrt(mean_squared_error(unscaledtestY[0], unscaledtestPredict[:,0]))  #Root mean squared error\n",
    "r2 = r2_score(unscaledtestY[0], unscaledtestPredict[:, 0]) #R2 score - This provides an indication of the goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model. It is the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "explained_variance = explained_variance_score(unscaledtestY[0], unscaledtestPredict[:, 0])  #Explained variance score  this measures the proportion to which a mathematical model accounts for the variation (dispersion) of a given data set. It is the proportion of the variance in the dependent variable that is predictable from the independent variables\n",
    "medae = median_absolute_error(unscaledtestY[0], unscaledtestPredict[:, 0])\n",
    "mae = mean_absolute_error(unscaledtestY[0], unscaledtestPredict[:, 0])\n",
    "mape = np.mean(np.abs((unscaledtestY[0] - unscaledtestPredict[:, 0]) / unscaledtestY[0])) * 100\n",
    "\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "print('R2 Score: %.2f' % (r2))\n",
    "print('Explained Variance: %.2f' % (explained_variance))\n",
    "print('Median Absolute Error: %.2f' % (medae))\n",
    "print('Mean Absolute Error: %.2f' % (mae))\n",
    "print('Mean Absolute Percentage Error: %.2f' % (mape)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifts predicitons and plots graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shift train predictions for plotting\n",
    "# trainPredictPlot = np.empty_like(dataset)\n",
    "\n",
    "# trainPredictPlot[:, :] = np.nan\n",
    "\n",
    "# #trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"LSTM - Predicted vs Actual\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.plot(unscaledtestPredict , label = \"Predicted\") #yÌ„\n",
    "plt.plot(rowunscaledtestY, label = \"Actual\") #ground truth values\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "print(testScore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
